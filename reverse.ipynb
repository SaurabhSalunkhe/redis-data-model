{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "343bdb26-051e-4cec-9691-03c25f3e252b",
   "metadata": {},
   "source": [
    "## Insert and Retrieve 10,000 Numbers with Redis\n",
    "\n",
    "### Requirements\n",
    "\n",
    "1. Insert numbers 1 to 10,000 into Redis (Server A)\n",
    "2. Retrieve and print them in reverse order from Redis Enterprise (Server B)\n",
    "\n",
    "---\n",
    "\n",
    "### Chosen Redis Data Type: `List`\n",
    "\n",
    "We use a Redis **List** to store the sequence of numbers because:\n",
    "\n",
    "- Redis Lists maintain insertion order\n",
    "- We can append values efficiently using `RPUSH`\n",
    "\n",
    "### Data Synchronization\n",
    "\n",
    "We have configured **Server B (Redis Enterprise)** as a **replica** of **Server A**\n",
    "\n",
    "This allows data written to Server A to automatically replicate to Server B in real time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42b04404-d3ba-4fb5-9041-043a0744eaf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c68b0743-456b-4ab3-aa33-16630b9e0a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Server A (Open Source Redis)\n",
    "import redis\n",
    "\n",
    "r1 = redis.Redis(\n",
    "    host=os.environ['REDIS_SERVER1_IP'],\n",
    "    port=6379,\n",
    "    password=os.environ['REDIS_SERVER1_PASSWORD'],\n",
    "    decode_responses=True\n",
    ")\n",
    "\n",
    "# Connect to Server B (Redis Enterprise)\n",
    "r2 = redis.Redis(\n",
    "    host=os.environ['REDIS_SERVER2_IP'],\n",
    "    port=10878,\n",
    "    decode_responses=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59a8888-2688-4fa6-94e4-9b43d2d76a8a",
   "metadata": {},
   "source": [
    "## We use the pipeline feature in redis-py which lets batch multiple Redis commands so they are sent in one network request instead of one at a time. \n",
    "\n",
    "## It allows executing thousands of redis commands using the pipe.execute() command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac38426-41e8-45b4-8e57-83fef80b4720",
   "metadata": {},
   "source": [
    "## We use the `RPUSH` command to insert values at the tail of the list.\n",
    "This ensures that the first value inserted (1) stays at index 0, and the last value (10,000) ends up at the last index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "020ffa1f-3a70-42dc-82b1-b65e19b1a0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 10,000 numbers into Server A.\n"
     ]
    }
   ],
   "source": [
    "r1.delete(\"numbers:list\")  # Clear old data if present\n",
    "\n",
    "pipe = r1.pipeline()\n",
    "for i in range(1, 10001):\n",
    "    pipe.rpush(\"numbers:list\", i)\n",
    "pipe.execute()\n",
    "\n",
    "print(\"Inserted 10,000 numbers into Server A.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d54518d9-6576-486e-b483-3b0cf2e8bdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server 2 numbers:list length: 10000\n",
      "First 5 values in reverse order: ['10000', '9999', '9998', '9997', '9996']\n"
     ]
    }
   ],
   "source": [
    "values = r2.lrange('numbers:list', 0, -1)\n",
    "print(\"Server 2 numbers:list length:\", len(values))\n",
    "print(\"First 5 values in reverse order:\", list(reversed(values))[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ded59e2-cdb7-47b1-a16f-fb8bd58d7386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elements in list: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Total elements in list:\", r2.llen(\"numbers:list\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2ce78f-279b-400f-ae70-568eacc44442",
   "metadata": {},
   "source": [
    "## Summary on inserting millions of values\n",
    "\n",
    "Redis processes commands with a **single‐threaded** event loop, trading parallelism for simplicity and atomicity, yet achieves **sub‑millisecond latency** by keeping all data in memory. To ingest **hundreds of millions** of items at high throughput, we combine **parallelization** (multiple client threads + pipelining) and **sharding** (Redis Cluster) to fully utilize network, CPU, and memory bandwidth without introducing wait time. \n",
    "On the read side, we choose data structures (`LIST` with `LPUSH`/`LRANGE` or `SORTED SET` with `ZADD`/`ZREVRANGE`) that naturally return **newest‐first**, and we coordinate consumer clients to pull from each shard and merge in reverse chronological order.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Leveraging Parallelization & Shards\n",
    "\n",
    "### 1. Parallelization via Client‑Side Threads & Pipelines\n",
    "\n",
    "Even though Redis is single‑threaded, we can **overlap** client CPU work (building commands) with server execution by using multiple application threads:\n",
    "\n",
    "- **Threads** in your producer program (Python/Java/Go) each maintain their own Redis‐client connection.  \n",
    "- Each thread **buffers** a batch (e.g. 5 000–50 000) of `LPUSH` or `ZADD` commands in a pipeline.  \n",
    "- While Redis processes one batch, **other threads** prepare and send their next batches, keeping the server’s event loop fully saturated\n",
    "\n",
    "### 2. Sharding with Redis Cluster\n",
    "\n",
    "To go beyond one core:\n",
    "\n",
    "1. **Redis Cluster** splits the keyspace into **16 384 hash slots**, assigning each slot to a different node (shard) \n",
    "2. The client library computes each key’s slot and routes commands to the correct node, so writes to `numbers:shard:3` go to Shard 3, `:shard:7` to Shard 7, etc.  \n",
    "3. This multiplies throughput by the number of nodes—each running its own single‑threaded event loop on a separate core\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d78ddb8-13d2-4776-bd6f-5d5839acace5",
   "metadata": {},
   "source": [
    "## Sorted Sets option\n",
    "\n",
    "You can use **Sorted Sets** to maintain strict insertion order by using each numeric ID as both the member and its score—so that\n",
    "ZREVRANGE myzset 0 -1 automatically returns the highest (newest) IDs first. In a Redis Cluster, shard your data into keys like myzset:{0}, myzset:{1}, … to distribute across nodes, with the RedisCluster client handling routing of each ZADD. Producers and consumers each run in their own threads or processes with dedicated connections—producers pipeline batched ZADD calls to their shard to maximize throughput, while consumers page through ZREVRANGE on each shard and merge or process results in reverse chronological order. This pattern scales horizontally across cores and nodes and preserves strict ordering, at the cost of O(log N) write complexity and additional memory overhead for scores and indexes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eabb23-3b83-459d-838f-6912c4871645",
   "metadata": {},
   "source": [
    "## AMR vs Elastic Cache\n",
    "Azure Cache for Redis (AMR) runs the official Redis Enterprise engine, so you get built‑in modules like RediSearch, RedisJSON and RedisBloom. Amazon ElastiCache uses open‑source Redis (or AWS Valkey for optional multi‑threading) and does not include these enterprise modules\n",
    "\n",
    "AMR supports active‑active geo‑replication for multi‑region read/write with conflict resolution, and offers an Enterprise Flash tier up to 4.5 TB on NVMe SSDs. ElastiCache only provides passive (read‑only) replicas in secondary regions and is strictly in‑memory.\n",
    "\n",
    "Because of its module support, active‑active replication, and flash storage, AMR is ideal for advanced caching, AI/ML feature stores, and large‑scale apps. ElastiCache remains a solid, cost‑effective choice for basic caching, session storage, and general‑purpose Redis workloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8296baf-3a1f-4ca0-9ded-3d2399e0f862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
